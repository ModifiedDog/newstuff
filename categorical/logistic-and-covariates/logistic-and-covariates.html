<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<style>
/* CSS for Markstat 2.0 using Pandoc 2.0 */
body{padding:14px 28px;}
body, table {font-family: Helvetica, Arial, Sans-serif; font-size: 14px;}
h1, h2, h3, h4 {font-weight: normal; color: #3366cc}
h1 {font-size: 200%;}
h2 {font-size: 150%;}
h3 {font-size: 120%;}
h4 {font-size: 100%; font-weight:bold}
img.center {display:block; margin-left:auto; margin-right:auto}
.small{font-size:8pt;}
a {color: black;}
a:visited {color: #808080;}
a.plain {text-decoration:none;}
a.plain:hover {text-decoration:underline;}
.em {font-weight:bold;}
pre, code {font-family: "lucida console", monospace;}
pre.stata {font-size:13px; line-height:13px;}
pre {padding:8px; border:1px solid #c0c0c0; border-radius:8px; background-color:#fdfdfd;}
code {color:#3366cc; background-color:#fafafa;}
pre code { color:black; background-color:white}
/* Added for Pandoc */
figure > img, div.figure > img {display:block; margin:auto}
figcaption, p.caption {text-align:center; font-weight:bold; color:#3366cc;}
h1.title {text-align:center; margin-bottom:0}
p.author, h2.author {font-style:italic; text-align:center;margin-top:4px;margin-bottom:0}
p.date, h3.date {text-align:center;margin-top:4px; margin-bottom:0}
/* Tables*/
table { margin:auto; border-collapse:collapse; }
table caption { margin-bottom:1ex;}
th, td { padding:4px 6px;}
thead tr:first-child th {border-top:1px solid black; padding-top:6px}
thead tr:last-child  th {padding-bottom:6px}
tbody tr:first-child td {border-top:1px solid black; padding-top:6px}
tbody tr:last-child  td {padding-bottom:6px;}
table tbody:last-child tr:last-child td {border-bottom:1px solid black;}
</style>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Andy Grogan-Kaylor" />
  <title>Logistic Regression With Covariates</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Logistic Regression With Covariates</h1>
<p class="author">Andy Grogan-Kaylor</p>
<p class="date">8 Sep 2020 16:08:06</p>
</header>
<style>h1 {color: #00274C;} h2 {color: #2F65A7;} blockquote {border-left: 5px solid #ffcb05; margin: 1.5em 10px; padding: 0.5em 10px;}</style>
<h1 id="background">Background</h1>
<h1 id="simulate-data">Simulate Data</h1>
<pre class='stata'>. clear all
</pre>
<pre class='stata'>. cd "/Users/agrogan/Desktop/newstuff/categorical/logistic-and-covariates"
/Users/agrogan/Desktop/newstuff/categorical/logistic-and-covariates
</pre>
<pre class='stata'>. set obs 1000
number of observations (_N) was 0, now 1,000
</pre>
<pre class='stata'>. generate x1 = rnormal() // normally distributed x
</pre>
<pre class='stata'>. histogram x1, scheme(michigan)
(bin=29, start=-3.1592772, width=.22074086)
</pre>
<pre class='stata'>. graph export histogram1.png, width(500) replace
(file histogram1.png written in PNG format)
</pre>
<figure>
<img src="histogram1.png" alt="" /><figcaption>Histogram of x1</figcaption>
</figure>
<pre class='stata'>. generate x2 = rnormal() // normally distributed z
</pre>
<pre class='stata'>. graph export histogram2.png, width(500) replace
(file histogram2.png written in PNG format)
</pre>
<figure>
<img src="histogram2.png" alt="" /><figcaption>Histogram of x2</figcaption>
</figure>
<pre class='stata'>. generate e = rnormal() // normally distributed error
</pre>
<pre class='stata'>. corr x1 x2 // x1 and x2 are uncorrelated
(obs=1,000)

             │       x1       x2
─────────────┼──────────────────
          x1 │   1.0000
          x2 │   0.0596   1.0000
</pre>
<pre class='stata'>. generate y1 = x1 + x2 + e // dependent variable
</pre>
<h1 id="linear-regression">Linear Regression</h1>
<pre class='stata'>. regress y1 x1

      Source │       SS           df       MS      Number of obs   =     1,000
─────────────┼──────────────────────────────────   F(1, 998)       =    635.15
       Model │  1289.80971         1  1289.80971   Prob > F        =    0.0000
    Residual │  2026.66544       998  2.03072689   R-squared       =    0.3889
─────────────┼──────────────────────────────────   Adj R-squared   =    0.3883
       Total │  3316.47515       999  3.31979494   Root MSE        =     1.425

─────────────┬────────────────────────────────────────────────────────────────
          y1 │      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
─────────────┼────────────────────────────────────────────────────────────────
          x1 │   1.088659   .0431971    25.20   0.000     1.003892    1.173427
       _cons │   .0278531   .0450746     0.62   0.537    -.0605987    .1163049
─────────────┴────────────────────────────────────────────────────────────────
</pre>
<pre class='stata'>. est store OLS1 // store estimates
</pre>
<pre class='stata'>. regress y1 x1 x2 

      Source │       SS           df       MS      Number of obs   =     1,000
─────────────┼──────────────────────────────────   F(2, 997)       =   1153.65
       Model │   2315.8002         2   1157.9001   Prob > F        =    0.0000
    Residual │  1000.67495       997    1.003686   R-squared       =    0.6983
─────────────┼──────────────────────────────────   Adj R-squared   =    0.6977
       Total │  3316.47515       999  3.31979494   Root MSE        =    1.0018

─────────────┬────────────────────────────────────────────────────────────────
          y1 │      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
─────────────┼────────────────────────────────────────────────────────────────
          x1 │   1.030682   .0304229    33.88   0.000     .9709817    1.090382
          x2 │   .9874388   .0308843    31.97   0.000     .9268331    1.048044
       _cons │   .0081816   .0316947     0.26   0.796    -.0540144    .0703775
─────────────┴────────────────────────────────────────────────────────────────
</pre>
<pre class='stata'>. est store OLS2 // store estimates
</pre>
<pre class='stata'>. estimates table OLS1 OLS2, b(%7.4f) star // table comparing estimates

─────────────┬──────────────────────────
    Variable │    OLS1         OLS2     
─────────────┼──────────────────────────
          x1 │  1.0887***    1.0307***  
          x2 │               0.9874***  
       _cons │  0.0279       0.0082     
─────────────┴──────────────────────────
legend: * p&lt;0.05; ** p&lt;0.01; *** p&lt;0.001
</pre>
<h1 id="logistic-regression">Logistic Regression</h1>
<pre class='stata'>. generate prob_y2 = exp(x1 + x2 + e) / (1 + exp(x1 + x2 + e))
</pre>
<pre class='stata'>. recode prob_y2 (0/.5 =0)(.5/1 = 1), generate(y2) // recode probabilites as observed val
> ues
(1000 differences between prob_y2 and y2)
</pre>
<pre class='stata'>. logit y2 x1

Iteration 0:   log likelihood = -693.11518  
Iteration 1:   log likelihood = -550.43417  
Iteration 2:   log likelihood = -550.34901  
Iteration 3:   log likelihood = -550.34899  

Logistic regression                             Number of obs     =      1,000
                                                LR chi2(1)        =     285.53
                                                Prob > chi2       =     0.0000
Log likelihood = -550.34899                     Pseudo R2         =     0.2060

─────────────┬────────────────────────────────────────────────────────────────
          y2 │      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
─────────────┼────────────────────────────────────────────────────────────────
          x1 │   1.282626   .0926296    13.85   0.000     1.101075    1.464177
       _cons │   .0044323   .0733194     0.06   0.952     -.139271    .1481356
─────────────┴────────────────────────────────────────────────────────────────
</pre>
<pre class='stata'>. est store logit1
</pre>
<pre class='stata'>. logit y2 x1 x2

Iteration 0:   log likelihood = -693.11518  
Iteration 1:   log likelihood = -399.88043  
Iteration 2:   log likelihood = -399.52919  
Iteration 3:   log likelihood = -399.52837  
Iteration 4:   log likelihood = -399.52837  

Logistic regression                             Number of obs     =      1,000
                                                LR chi2(2)        =     587.17
                                                Prob > chi2       =     0.0000
Log likelihood = -399.52837                     Pseudo R2         =     0.4236

─────────────┬────────────────────────────────────────────────────────────────
          y2 │      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
─────────────┼────────────────────────────────────────────────────────────────
          x1 │    1.80266   .1291406    13.96   0.000     1.549549    2.055771
          x2 │   1.644651   .1215883    13.53   0.000     1.406342     1.88296
       _cons │   -.060496   .0882002    -0.69   0.493    -.2333652    .1123732
─────────────┴────────────────────────────────────────────────────────────────
</pre>
<pre class='stata'>. est store logit2
</pre>
<pre class='stata'>. estimates table logit1 logit2, b(%7.4f) star // table comparing estimates

─────────────┬──────────────────────────
    Variable │   logit1       logit2    
─────────────┼──────────────────────────
          x1 │  1.2826***    1.8027***  
          x2 │               1.6447***  
       _cons │  0.0044      -0.0605     
─────────────┴──────────────────────────
legend: * p&lt;0.05; ** p&lt;0.01; *** p&lt;0.001
</pre>
<h1 id="references">References</h1>
<p>I’ve been inspired in this disussion by Jonathan Bartlett’s discussion of these issues: <a href="https://thestatsgeek.com/2017/05/11/odds-ratios-collapsibility-marginal-vs-conditional-gee-vs-glmms/">https://thestatsgeek.com/2017/05/11/odds-ratios-collapsibility-marginal-vs-conditional-gee-vs-glmms/</a></p>
</body>
</html>
