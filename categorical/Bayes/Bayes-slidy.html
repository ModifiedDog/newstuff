<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Andy Grogan-Kaylor" />
  <title>Bayesian Categorical Data Analysis</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
   href="../UNslidy.css" />
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
	<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Bayesian Categorical Data Analysis</h1>
  <p class="author">
Andy Grogan-Kaylor
  </p>
</div>
<div class="slide section level2">

<p>Andy Grogan-Kaylor</p>
<p>16 Jul 2020 15:42:27</p>
</div>
<div id="introduction" class="title-slide slide section level1"><h1>Introduction</h1><div class="sourceCode" id="cb1"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb1-1"><a href="#cb1-1"></a>. <span class="kw">clear</span> <span class="ot">all</span></span></code></pre></div></div>
<div id="the-importance-of-thinking-about-prior-information" class="title-slide slide section level1"><h1>The Importance of Thinking About Prior Information</h1><blockquote>
<p><a href="https://agrogan.shinyapps.io/Thinking-Through-Bayes/">Thinking Through Bayesian Ideas</a></p>
</blockquote></div>
<div id="more-about-priors-from-sas-corporation" class="title-slide slide section level1"><h1>More About Priors From SAS Corporation</h1><blockquote>
<p>“In addition to data, analysts often have at their disposal useful auxiliary information about inputs into their model—for example, knowledge that high prices typically decrease demand or that sunny weather increases outdoor mall foot traffic. If used and incorporated correctly into the analysis, the auxiliary information can significantly improve the quality of the analysis. But this information is often ignored. Bayesian analysis provides a principled means of incorporating this information into the model through the prior distribution, but it does not provide a road map for translating auxiliary information into a useful prior.”</p>
</blockquote>
<p>–SAS Corporation</p></div>
<div id="formal-derivation-of-bayes-theorem" class="title-slide slide section level1"><h1>Formal Derivation of Bayes Theorem</h1><blockquote>
<p>Following inspiration from Kruschke (2011).</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th align="left">Probability</th>
<th align="right">A</th>
<th align="right">Not A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">B</td>
<td align="right"><span class="math inline">\(P_1\)</span></td>
<td align="right"><span class="math inline">\(P_2\)</span></td>
</tr>
<tr class="even">
<td align="left">Not B</td>
<td align="right"><span class="math inline">\(P_3\)</span></td>
<td align="right"><span class="math inline">\(P_4\)</span></td>
</tr>
</tbody>
</table>
<p>Filling in the probabilities.</p>
<table>
<thead>
<tr class="header">
<th align="left">Probability</th>
<th align="left">A</th>
<th align="left">Not A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">B</td>
<td align="left"><span class="math inline">\(P(A, B)\)</span></td>
<td align="left"><span class="math inline">\(P(\text{not} A, B)\)</span></td>
</tr>
<tr class="even">
<td align="left">Not B</td>
<td align="left"><span class="math inline">\(P(A, \text{not} B)\)</span></td>
<td align="left"><span class="math inline">\(P(\text{not} A, \text{not} B)\)</span></td>
</tr>
</tbody>
</table>
<p>From the definition of conditional probability:</p>
<p><span class="math inline">\(P(A|B) = P(A,B) / P(B)\)</span></p>
<p><span class="math inline">\(P(B|A) = P(A,B) / P(A)\)</span></p>
<p>Then:</p>
<p><span class="math inline">\(P(A|B)P(B) = P(A,B)\)</span></p>
<p><span class="math inline">\(P(B|A)P(A) = P(A,B)\)</span></p>
<p>Then:</p>
<p><span class="math inline">\(P(A|B)P(B) = P(B|A)P(A)\)</span></p>
<p>Then:</p>
<p><span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span></p></div>
<div id="applying-the-derivation-to-data-analysis" class="title-slide slide section level1"><h1>Applying the Derivation to Data Analysis</h1><table>
<thead>
<tr class="header">
<th align="left">Probability</th>
<th align="left">Data</th>
<th align="left">Not Data</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Hypothesis</td>
<td align="left"><span class="math inline">\(P(D, H)\)</span></td>
<td align="left"><span class="math inline">\(P(\text{not} D, H)\)</span></td>
</tr>
<tr class="even">
<td align="left">Not Hypothesis</td>
<td align="left"><span class="math inline">\(P(D, \text{not} H)\)</span></td>
<td align="left"><span class="math inline">\(P(\text{not} D, \text{not} H)\)</span></td>
</tr>
</tbody>
</table>
<p>From the definition of conditional probability:</p>
<p><span class="math inline">\(P(D|H) = P(D,H) / P(H)\)</span></p>
<p><span class="math inline">\(P(H|D) = P(D,H) / P(D)\)</span></p>
<p>Then:</p>
<p><span class="math inline">\(P(D|H)P(H) = P(D,H)\)</span></p>
<p><span class="math inline">\(P(H|D)P(D) = P(D,H)\)</span></p>
<p>Then:</p>
<p><span class="math inline">\(P(D|H)P(H) = P(H|D)P(D)\)</span></p>
<p>Then:</p>
<p><span class="math inline">\(P(H|D) = \frac{P(D|H)P(H)}{P(D)}\)</span></p>
<p><span class="math inline">\(\text{posterior} \sim \text{likelihood} \times \text{prior}\)</span></p></div>
<div id="accepting-the-null-hypothesis" class="title-slide slide section level1"><h1>Accepting the Null Hypothesis</h1></div><div id="we-are-directly-estimating-the-probability-of-the-hypothesis-given-the-data" class="slide section level2">
<h1>We Are Directly Estimating The Probability of the Hypothesis Given The Data</h1>
<ul class="incremental">
<li>Could be large e.g. .8.</li>
<li>Could be small e.g. .1.</li>
<li>Could be effectively 0. (<em>Essentially, we can accept a null hypothesis</em>)</li>
</ul>
</div><div id="we-are-not-rejecting-a-null-hypothesis" class="slide section level2">
<h1>We Are <em>Not</em> Rejecting a Null Hypothesis</h1>
<p>We are <em>not</em> imagining a hypothetical <em>null hypothesis</em> (<em>that may not even be substantively meaningful</em>), and asking the question of whether the data we observe are extreme enough that we wish to reject this null hypothesis.</p>
<ul class="incremental">
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\bar{x} = 0\)</span> or <span class="math inline">\(\beta = 0\)</span></li>
<li>Posit <span class="math inline">\(H_A\)</span>: <span class="math inline">\(\bar{x} \neq 0\)</span> or <span class="math inline">\(\beta \neq 0\)</span></li>
<li>Observe data and calculate a test statistic (e.g. <span class="math inline">\(t\)</span>). If <span class="math inline">\(\text{test statistic} &gt; \text{critical value}\)</span>, e.g. <span class="math inline">\(t &gt; 1.96\)</span> then reject <span class="math inline">\(H_0\)</span>.</li>
<li>We can never <em>accept</em> <span class="math inline">\(H_0\)</span>, only <em>reject</em> <span class="math inline">\(H_A\)</span>.</li>
</ul>
</div><div id="accepting-null-hypotheses" class="slide section level2">
<h1>Accepting Null Hypotheses</h1>
<p>What is the effect on science and publication of having a statistical practice where we can never affirm <span class="math inline">\(\bar{x} = 0\)</span> or <span class="math inline">\(\beta = 0\)</span>, but only reject <span class="math inline">\(\bar{x} = 0\)</span> or <span class="math inline">\(\beta = 0\)</span>?</p>
<ul class="incremental">
<li>Only affirm difference not similarity</li>
<li>Publication bias</li>
</ul>
<blockquote>
<p>See <a href="https://agrogan1.github.io/Bayes/accepting-H0/accepting-H0.html">https://agrogan1.github.io/Bayes/accepting-H0/accepting-H0.html</a></p>
</blockquote>
<blockquote>
<p>Bayesian statistics allow us to accept the null hypothesis <span class="math inline">\(H_0\)</span>.</p>
</blockquote>
</div>
<div id="bayesian-categorical-data-analysis-in-stata" class="title-slide slide section level1"><h1>Bayesian Categorical Data Analysis in Stata</h1><div class="sourceCode" id="cb2"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb2-1"><a href="#cb2-1"></a>. <span class="kw">clear</span> <span class="ot">all</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb3-1"><a href="#cb3-1"></a>. <span class="kw">use</span> <span class="st">&quot;../logistic-regression/GSSsmall.dta&quot;</span>, <span class="kw">clear</span></span></code></pre></div></div><div id="frequentist-logistic-regression" class="slide section level2">
<h1>Frequentist Logistic Regression</h1>
<div class="sourceCode" id="cb4"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb4-1"><a href="#cb4-1"></a>. <span class="kw">logit</span> liberal i.race i.<span class="kw">class</span></span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a>Iteration 0:   <span class="fu">log</span> likelihood = -31538.733  </span>
<span id="cb4-4"><a href="#cb4-4"></a>Iteration 1:   <span class="fu">log</span> likelihood = -31370.507  </span>
<span id="cb4-5"><a href="#cb4-5"></a>Iteration 2:   <span class="fu">log</span> likelihood = -31369.841  </span>
<span id="cb4-6"><a href="#cb4-6"></a>Iteration 3:   <span class="fu">log</span> likelihood = -31369.841  </span>
<span id="cb4-7"><a href="#cb4-7"></a></span>
<span id="cb4-8"><a href="#cb4-8"></a>Logistic regression                             Number <span class="kw">of</span> <span class="kw">obs</span>     =     53,625</span>
<span id="cb4-9"><a href="#cb4-9"></a>                                                LR <span class="fu">chi2</span>(5)        =     337.78</span>
<span id="cb4-10"><a href="#cb4-10"></a>                                                Prob &gt; <span class="fu">chi2</span>       =     0.0000</span>
<span id="cb4-11"><a href="#cb4-11"></a>Log likelihood = -31369.841                     Pseudo R2         =     0.0054</span>
<span id="cb4-12"><a href="#cb4-12"></a></span>
<span id="cb4-13"><a href="#cb4-13"></a>───────────────┬────────────────────────────────────────────────────────────────</span>
<span id="cb4-14"><a href="#cb4-14"></a>       liberal │      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]</span>
<span id="cb4-15"><a href="#cb4-15"></a>───────────────┼────────────────────────────────────────────────────────────────</span>
<span id="cb4-16"><a href="#cb4-16"></a>          race │</span>
<span id="cb4-17"><a href="#cb4-17"></a>        <span class="bn">black</span>  │   .4443531   .0272062    16.33   0.000       .39103    .4976762</span>
<span id="cb4-18"><a href="#cb4-18"></a>        other  │   .3190896   .0413275     7.72   0.000     .2380891    .4000901</span>
<span id="cb4-19"><a href="#cb4-19"></a>               │</span>
<span id="cb4-20"><a href="#cb4-20"></a>         <span class="kw">class</span> │</span>
<span id="cb4-21"><a href="#cb4-21"></a>working <span class="kw">class</span>  │  -.1397848    .041515    -3.37   0.001    -.2211527   -.0584169</span>
<span id="cb4-22"><a href="#cb4-22"></a> middle <span class="kw">class</span>  │  -.0117948   .0416509    -0.28   0.777     -.093429    .0698394</span>
<span id="cb4-23"><a href="#cb4-23"></a>  <span class="fu">upper</span> <span class="kw">class</span>  │   .1512565   .0648962     2.33   0.020     .0240624    .2784507</span>
<span id="cb4-24"><a href="#cb4-24"></a>               │</span>
<span id="cb4-25"><a href="#cb4-25"></a>         <span class="dt">_cons</span> │  -.9900441   .0397384   -24.91   0.000     -1.06793   -.9121582</span>
<span id="cb4-26"><a href="#cb4-26"></a>───────────────┴────────────────────────────────────────────────────────────────</span></code></pre></div>
</div><div id="bayesian-logistic-regression" class="slide section level2">
<h1>Bayesian Logistic Regression</h1>
<blockquote>
<p>Takes a few minutes since using MCMC (5-10 minutes).</p>
</blockquote>
<div class="sourceCode" id="cb5"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb5-1"><a href="#cb5-1"></a>. <span class="kw">sample</span> 10 <span class="co">// Random Sample To Speed This Example: DON&#39;T DO THIS IN PRACTICE!!!</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>(58,332 observations deleted)</span></code></pre></div>
<blockquote>
<p>How do we interpret the result for some of the <strong>social class</strong> categories where the credibility interval includes 0?</p>
</blockquote>
<div class="sourceCode" id="cb6"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb6-1"><a href="#cb6-1"></a>. bayes: <span class="kw">logit</span> liberal i.race i.<span class="kw">class</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>  </span>
<span id="cb6-3"><a href="#cb6-3"></a>Burn-<span class="kw">in</span> ...</span>
<span id="cb6-4"><a href="#cb6-4"></a>Simulation ...</span>
<span id="cb6-5"><a href="#cb6-5"></a></span>
<span id="cb6-6"><a href="#cb6-6"></a>Model summary</span>
<span id="cb6-7"><a href="#cb6-7"></a>────────────────────────────────────────────────────────────────────────────────</span>
<span id="cb6-8"><a href="#cb6-8"></a>Likelihood: </span>
<span id="cb6-9"><a href="#cb6-9"></a>  liberal ~ <span class="kw">logit</span>(xb_liberal)</span>
<span id="cb6-10"><a href="#cb6-10"></a></span>
<span id="cb6-11"><a href="#cb6-11"></a>Prior: </span>
<span id="cb6-12"><a href="#cb6-12"></a>  {liberal:i.race i.<span class="kw">class</span> <span class="dt">_cons</span>} ~ <span class="fu">normal</span>(0,10000)                           (1)</span>
<span id="cb6-13"><a href="#cb6-13"></a>────────────────────────────────────────────────────────────────────────────────</span>
<span id="cb6-14"><a href="#cb6-14"></a>(1) Parameters are elements <span class="kw">of</span> the linear form xb_liberal.</span>
<span id="cb6-15"><a href="#cb6-15"></a></span>
<span id="cb6-16"><a href="#cb6-16"></a>Bayesian <span class="kw">logistic</span> regression                       MCMC iterations  =     12,500</span>
<span id="cb6-17"><a href="#cb6-17"></a>Random-walk Metropolis-Hastings sampling           Burn-<span class="kw">in</span>          =      2,500</span>
<span id="cb6-18"><a href="#cb6-18"></a>                                                   MCMC <span class="kw">sample</span> <span class="kw">size</span> =     10,000</span>
<span id="cb6-19"><a href="#cb6-19"></a>                                                   Number <span class="kw">of</span> <span class="kw">obs</span>    =      5,393</span>
<span id="cb6-20"><a href="#cb6-20"></a>                                                   Acceptance rate  =      .2257</span>
<span id="cb6-21"><a href="#cb6-21"></a>                                                   Efficiency:  <span class="fu">min</span> =     .01383</span>
<span id="cb6-22"><a href="#cb6-22"></a>                                                                avg =     .03232</span>
<span id="cb6-23"><a href="#cb6-23"></a>Log marginal likelihood = -3180.1718                            <span class="fu">max</span> =      .0583</span>
<span id="cb6-24"><a href="#cb6-24"></a> </span>
<span id="cb6-25"><a href="#cb6-25"></a>───────────────┬────────────────────────────────────────────────────────────────</span>
<span id="cb6-26"><a href="#cb6-26"></a>               │                                                Equal-tailed</span>
<span id="cb6-27"><a href="#cb6-27"></a>       liberal │      Mean   Std. Dev.     MCSE     Median  [95% Cred. Interval]</span>
<span id="cb6-28"><a href="#cb6-28"></a>───────────────┼────────────────────────────────────────────────────────────────</span>
<span id="cb6-29"><a href="#cb6-29"></a>          race │</span>
<span id="cb6-30"><a href="#cb6-30"></a>        <span class="bn">black</span>  │  .3947493   .0822819   .005895   .3933429   .2289023   .5567789</span>
<span id="cb6-31"><a href="#cb6-31"></a>        other  │  .5018242   .1295803   .011017    .503707    .255992   .7522975</span>
<span id="cb6-32"><a href="#cb6-32"></a>               │</span>
<span id="cb6-33"><a href="#cb6-33"></a>         <span class="kw">class</span> │</span>
<span id="cb6-34"><a href="#cb6-34"></a>working <span class="kw">class</span>  │ -.4241844   .1243631   .007727   -.422026  -.6713128    -.20072</span>
<span id="cb6-35"><a href="#cb6-35"></a> middle <span class="kw">class</span>  │ -.2619162   .1232291   .006378  -.2664475  -.5197306  -.0254913</span>
<span id="cb6-36"><a href="#cb6-36"></a>  <span class="fu">upper</span> <span class="kw">class</span>  │ -.1508993   .1983133   .010032  -.1534356  -.5326012   .2457839</span>
<span id="cb6-37"><a href="#cb6-37"></a>               │</span>
<span id="cb6-38"><a href="#cb6-38"></a>         <span class="dt">_cons</span> │ -.7522187   .1149148   .004759  -.7508257  -.9723163  -.5232482</span>
<span id="cb6-39"><a href="#cb6-39"></a>───────────────┴────────────────────────────────────────────────────────────────</span>
<span id="cb6-40"><a href="#cb6-40"></a>Note: Default priors are used <span class="kw">for</span> <span class="kw">model</span> parameters.</span></code></pre></div>
</div><div id="blocking-may-improve-estimation" class="slide section level2">
<h1>Blocking May Improve Estimation</h1>
<div class="sourceCode" id="cb7"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb7-1"><a href="#cb7-1"></a>. * bayes, block({liberal:i.race}): <span class="kw">logit</span> liberal i.race i.<span class="kw">class</span> <span class="co">// blocking may improve </span></span>
<span id="cb7-2"><a href="#cb7-2"></a>&gt; estimation</span></code></pre></div>
</div><div id="bayesian-logistic-regression-with-priors" class="slide section level2">
<h1>Bayesian Logistic Regression With Priors</h1>
<p>Priors:</p>
<ul class="incremental">
<li>Encode prior information: strong theory; strong clinical or practice wisdom; strong previous empirical results.</li>
<li>May be helpful in quantitatively encoding the results of prior literature.</li>
<li>May be especially helpful when your sample is small.</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb8-1"><a href="#cb8-1"></a>. bayes, normalprior(5): <span class="kw">logit</span> liberal i.race i.<span class="kw">class</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>  </span>
<span id="cb8-3"><a href="#cb8-3"></a>Burn-<span class="kw">in</span> ...</span>
<span id="cb8-4"><a href="#cb8-4"></a>Simulation ...</span>
<span id="cb8-5"><a href="#cb8-5"></a></span>
<span id="cb8-6"><a href="#cb8-6"></a>Model summary</span>
<span id="cb8-7"><a href="#cb8-7"></a>────────────────────────────────────────────────────────────────────────────────</span>
<span id="cb8-8"><a href="#cb8-8"></a>Likelihood: </span>
<span id="cb8-9"><a href="#cb8-9"></a>  liberal ~ <span class="kw">logit</span>(xb_liberal)</span>
<span id="cb8-10"><a href="#cb8-10"></a></span>
<span id="cb8-11"><a href="#cb8-11"></a>Prior: </span>
<span id="cb8-12"><a href="#cb8-12"></a>  {liberal:i.race i.<span class="kw">class</span> <span class="dt">_cons</span>} ~ <span class="fu">normal</span>(0,25)                              (1)</span>
<span id="cb8-13"><a href="#cb8-13"></a>────────────────────────────────────────────────────────────────────────────────</span>
<span id="cb8-14"><a href="#cb8-14"></a>(1) Parameters are elements <span class="kw">of</span> the linear form xb_liberal.</span>
<span id="cb8-15"><a href="#cb8-15"></a></span>
<span id="cb8-16"><a href="#cb8-16"></a>Bayesian <span class="kw">logistic</span> regression                       MCMC iterations  =     12,500</span>
<span id="cb8-17"><a href="#cb8-17"></a>Random-walk Metropolis-Hastings sampling           Burn-<span class="kw">in</span>          =      2,500</span>
<span id="cb8-18"><a href="#cb8-18"></a>                                                   MCMC <span class="kw">sample</span> <span class="kw">size</span> =     10,000</span>
<span id="cb8-19"><a href="#cb8-19"></a>                                                   Number <span class="kw">of</span> <span class="kw">obs</span>    =      5,393</span>
<span id="cb8-20"><a href="#cb8-20"></a>                                                   Acceptance rate  =      .2018</span>
<span id="cb8-21"><a href="#cb8-21"></a>                                                   Efficiency:  <span class="fu">min</span> =     .01531</span>
<span id="cb8-22"><a href="#cb8-22"></a>                                                                avg =      .0254</span>
<span id="cb8-23"><a href="#cb8-23"></a>Log marginal likelihood = -3162.2981                            <span class="fu">max</span> =     .04229</span>
<span id="cb8-24"><a href="#cb8-24"></a> </span>
<span id="cb8-25"><a href="#cb8-25"></a>───────────────┬────────────────────────────────────────────────────────────────</span>
<span id="cb8-26"><a href="#cb8-26"></a>               │                                                Equal-tailed</span>
<span id="cb8-27"><a href="#cb8-27"></a>       liberal │      Mean   Std. Dev.     MCSE     Median  [95% Cred. Interval]</span>
<span id="cb8-28"><a href="#cb8-28"></a>───────────────┼────────────────────────────────────────────────────────────────</span>
<span id="cb8-29"><a href="#cb8-29"></a>          race │</span>
<span id="cb8-30"><a href="#cb8-30"></a>        <span class="bn">black</span>  │  .4063884   .0830629   .004039   .4098444   .2476307   .5649653</span>
<span id="cb8-31"><a href="#cb8-31"></a>        other  │  .5087264   .1206866   .007204   .5028487   .2772664   .7407117</span>
<span id="cb8-32"><a href="#cb8-32"></a>               │</span>
<span id="cb8-33"><a href="#cb8-33"></a>         <span class="kw">class</span> │</span>
<span id="cb8-34"><a href="#cb8-34"></a>working <span class="kw">class</span>  │ -.4232222   .1221491   .008601   -.424899  -.6637786  -.1720494</span>
<span id="cb8-35"><a href="#cb8-35"></a> middle <span class="kw">class</span>  │ -.2570835   .1197257   .009677  -.2614378  -.4845897  -.0119759</span>
<span id="cb8-36"><a href="#cb8-36"></a>  <span class="fu">upper</span> <span class="kw">class</span>  │  -.135455    .200802   .012247  -.1340006  -.5505343   .2664472</span>
<span id="cb8-37"><a href="#cb8-37"></a>               │</span>
<span id="cb8-38"><a href="#cb8-38"></a>         <span class="dt">_cons</span> │ -.7615401   .1153949   .008224  -.7556258   -.998298  -.5372218</span>
<span id="cb8-39"><a href="#cb8-39"></a>───────────────┴────────────────────────────────────────────────────────────────</span>
<span id="cb8-40"><a href="#cb8-40"></a>Note: Default priors are used <span class="kw">for</span> <span class="kw">model</span> parameters.</span></code></pre></div>
</div><div id="mcmc-vs.-ml" class="slide section level2">
<h1>MCMC vs. ML</h1>
<div class="sourceCode" id="cb9"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb9-1"><a href="#cb9-1"></a>. <span class="kw">clear</span> <span class="ot">all</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb10-1"><a href="#cb10-1"></a>. <span class="kw">set</span> <span class="kw">obs</span> 100</span>
<span id="cb10-2"><a href="#cb10-2"></a>number <span class="kw">of</span> observations (_N) was 0, now 100</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb11-1"><a href="#cb11-1"></a>. <span class="kw">generate</span> myestimate = rnormal() + 10 <span class="co">// simulated values of estimate</span></span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb12-1"><a href="#cb12-1"></a>. <span class="kw">summarize</span> myestimate</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a>    Variable │        Obs        Mean    Std. Dev.       Min        Max</span>
<span id="cb12-4"><a href="#cb12-4"></a>─────────────┼─────────────────────────────────────────────────────────</span>
<span id="cb12-5"><a href="#cb12-5"></a>  myestimate │        100     9.99037    .9061558   7.483831   11.92453</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb13-1"><a href="#cb13-1"></a>. <span class="kw">local</span> mymean = <span class="fu">r</span>(<span class="kw">mean</span>)</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb14-1"><a href="#cb14-1"></a>. <span class="kw">kdensity</span> myestimate ,  <span class="co">///</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>&gt; <span class="bn">title</span>(<span class="st">&quot;Likelihood of Estimate&quot;</span>) <span class="co">///</span></span>
<span id="cb14-3"><a href="#cb14-3"></a>&gt; <span class="bn">xtitle</span>(<span class="st">&quot;Estimate&quot;</span>) <span class="bn">ytitle</span>(<span class="st">&quot;Likelihood&quot;</span>) <span class="co">///</span></span>
<span id="cb14-4"><a href="#cb14-4"></a>&gt; <span class="kw">note</span>(<span class="st">&quot;Vertical Line At Mean Value&quot;</span>) <span class="co">///</span></span>
<span id="cb14-5"><a href="#cb14-5"></a>&gt; <span class="bn">caption</span>(<span class="st">&quot;ML gives point estimate; Bayes gives full range of distribution&quot;</span>) <span class="co">///</span></span>
<span id="cb14-6"><a href="#cb14-6"></a>&gt; <span class="bn">xline</span>(<span class="ot">`mymean&#39;</span>, lwidth(1) lcolor(<span class="bn">gold</span>)) <span class="dv">scheme</span>(michigan)</span></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb15-1"><a href="#cb15-1"></a>. <span class="kw">graph</span> <span class="kw">export</span> MCMC-ML.png, <span class="kw">width</span>(500) <span class="kw">replace</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>(file MCMC-ML.png written <span class="kw">in</span> PNG <span class="kw">format</span>)</span></code></pre></div>
<div class="figure">
<img src="MCMC-ML.png" alt="" />
<p class="caption">MCMC vs. ML</p>
</div>
</div><div id="full-distribution-of-parameters" class="slide section level2">
<h1>Full Distribution of Parameters</h1>
<div class="sourceCode" id="cb16"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb16-1"><a href="#cb16-1"></a>. <span class="kw">clear</span> <span class="ot">all</span></span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb17-1"><a href="#cb17-1"></a>. <span class="kw">use</span> <span class="st">&quot;../logistic-regression/GSSsmall.dta&quot;</span>, <span class="kw">clear</span></span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb18-1"><a href="#cb18-1"></a>. <span class="kw">sample</span> 10 <span class="co">// Random Sample for These Slides: DON&#39;T DO THIS IN PRACTICE!!!</span></span>
<span id="cb18-2"><a href="#cb18-2"></a>(58,332 observations deleted)</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb19-1"><a href="#cb19-1"></a>. bayes, normalprior(5): <span class="kw">logit</span> liberal i.race i.<span class="kw">class</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>  </span>
<span id="cb19-3"><a href="#cb19-3"></a>Burn-<span class="kw">in</span> ...</span>
<span id="cb19-4"><a href="#cb19-4"></a>Simulation ...</span>
<span id="cb19-5"><a href="#cb19-5"></a></span>
<span id="cb19-6"><a href="#cb19-6"></a>Model summary</span>
<span id="cb19-7"><a href="#cb19-7"></a>────────────────────────────────────────────────────────────────────────────────</span>
<span id="cb19-8"><a href="#cb19-8"></a>Likelihood: </span>
<span id="cb19-9"><a href="#cb19-9"></a>  liberal ~ <span class="kw">logit</span>(xb_liberal)</span>
<span id="cb19-10"><a href="#cb19-10"></a></span>
<span id="cb19-11"><a href="#cb19-11"></a>Prior: </span>
<span id="cb19-12"><a href="#cb19-12"></a>  {liberal:i.race i.<span class="kw">class</span> <span class="dt">_cons</span>} ~ <span class="fu">normal</span>(0,25)                              (1)</span>
<span id="cb19-13"><a href="#cb19-13"></a>────────────────────────────────────────────────────────────────────────────────</span>
<span id="cb19-14"><a href="#cb19-14"></a>(1) Parameters are elements <span class="kw">of</span> the linear form xb_liberal.</span>
<span id="cb19-15"><a href="#cb19-15"></a></span>
<span id="cb19-16"><a href="#cb19-16"></a>Bayesian <span class="kw">logistic</span> regression                       MCMC iterations  =     12,500</span>
<span id="cb19-17"><a href="#cb19-17"></a>Random-walk Metropolis-Hastings sampling           Burn-<span class="kw">in</span>          =      2,500</span>
<span id="cb19-18"><a href="#cb19-18"></a>                                                   MCMC <span class="kw">sample</span> <span class="kw">size</span> =     10,000</span>
<span id="cb19-19"><a href="#cb19-19"></a>                                                   Number <span class="kw">of</span> <span class="kw">obs</span>    =      5,345</span>
<span id="cb19-20"><a href="#cb19-20"></a>                                                   Acceptance rate  =      .2082</span>
<span id="cb19-21"><a href="#cb19-21"></a>                                                   Efficiency:  <span class="fu">min</span> =     .02443</span>
<span id="cb19-22"><a href="#cb19-22"></a>                                                                avg =     .03407</span>
<span id="cb19-23"><a href="#cb19-23"></a>Log marginal likelihood = -3105.9749                            <span class="fu">max</span> =     .06349</span>
<span id="cb19-24"><a href="#cb19-24"></a> </span>
<span id="cb19-25"><a href="#cb19-25"></a>───────────────┬────────────────────────────────────────────────────────────────</span>
<span id="cb19-26"><a href="#cb19-26"></a>               │                                                Equal-tailed</span>
<span id="cb19-27"><a href="#cb19-27"></a>       liberal │      Mean   Std. Dev.     MCSE     Median  [95% Cred. Interval]</span>
<span id="cb19-28"><a href="#cb19-28"></a>───────────────┼────────────────────────────────────────────────────────────────</span>
<span id="cb19-29"><a href="#cb19-29"></a>          race │</span>
<span id="cb19-30"><a href="#cb19-30"></a>        <span class="bn">black</span>  │  .5422929   .0827044   .004872   .5434182   .3823331   .7078339</span>
<span id="cb19-31"><a href="#cb19-31"></a>        other  │  .4157509   .1281866   .005087   .4171814    .163697   .6570723</span>
<span id="cb19-32"><a href="#cb19-32"></a>               │</span>
<span id="cb19-33"><a href="#cb19-33"></a>         <span class="kw">class</span> │</span>
<span id="cb19-34"><a href="#cb19-34"></a>working <span class="kw">class</span>  │ -.2171419   .1361014   .008708  -.2179448  -.4807177   .0627315</span>
<span id="cb19-35"><a href="#cb19-35"></a> middle <span class="kw">class</span>  │ -.1583411   .1396594   .008239  -.1582649  -.4454747   .1111331</span>
<span id="cb19-36"><a href="#cb19-36"></a>  <span class="fu">upper</span> <span class="kw">class</span>  │ -.0034842   .2229609   .012502  -.0032252  -.4430678   .4161878</span>
<span id="cb19-37"><a href="#cb19-37"></a>               │</span>
<span id="cb19-38"><a href="#cb19-38"></a>         <span class="dt">_cons</span> │ -.9453812   .1325399   .008048  -.9430257  -1.212341  -.6728245</span>
<span id="cb19-39"><a href="#cb19-39"></a>───────────────┴────────────────────────────────────────────────────────────────</span>
<span id="cb19-40"><a href="#cb19-40"></a>Note: Default priors are used <span class="kw">for</span> <span class="kw">model</span> parameters.</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb20-1"><a href="#cb20-1"></a>. bayesgraph <span class="kw">kdensity</span> {liberal:2.race}, <span class="dv">scheme</span>(michigan)</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb21-1"><a href="#cb21-1"></a>. <span class="kw">graph</span> <span class="kw">export</span> mybayesgraph.png, <span class="kw">width</span>(500) <span class="kw">replace</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>(file mybayesgraph.png written <span class="kw">in</span> PNG <span class="kw">format</span>)</span></code></pre></div>
<div class="figure">
<img src="mybayesgraph.png" alt="" />
<p class="caption">Density Plot of Parameter</p>
</div>
</div>
</body>
</html>
