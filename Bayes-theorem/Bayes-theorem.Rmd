---
title: "Bayes Theorem"
subtitle: "Applied To Data Analysis"
author: "Andy Grogan-Kaylor"
institute: "University of Michigan"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{css, echo=FALSE}

@import url('https://fonts.googleapis.com/css2?family=Montserrat&display=swap');
.title-slide { 
  color: #ffcb05;
  background-color: #00274C; 
}
.title-slide h1 {
    color: #ffcb05;
}
pre {
  white-space: pre-wrap;
}
h1, h2, h3 {
  font-family: 'Montserrat', sans-serif;
}
body { 
    font-family: 'Montserrat', sans-serif;
}
.author, .date {
  font-family: 'Montserrat', sans-serif;
}
blockquote { 
  border-left: 5px solid #ffcb05; 
  margin: 1.5em 10px; 
  padding: 0.5em 10px;
}
```

# How To Navigate This Presentation

Use the <span style="font-size:100px">&#8678;</span> and <span style="font-size:100px">&#8680;</span> keys to move through the presentation.

---
# Derivation

--

|               | D=1                  | D=0                             |
|:--------------|:---------------------|:--------------------------------|
| H=1           | $P(D, H)$            | $P(\text{not} D, H)$            |
| H=0           | $P(D, \text{not} H)$ | $P(\text{not} D, \text{not} H)$ |

--

From the definition of conditional probability: 

--

$P(D|H) = P(D,H) / P(H)$

--

$P(H|D) = P(D,H) / P(D)$

---
# Then: 

--

$P(D|H)P(H) = P(D,H)$

--

$P(H|D)P(D) = P(D,H)$

--

# Then:

$P(D|H)P(H) = P(H|D)P(D)$

--
Then:

$P(D|H) = \frac{P(H|D)P(D)}{P(H)}$ Bayes Theorem

--

$\text{posterior} \sim \text{likelihood} \times \text{prior}$ In words

---
# Expanded Version

--

$P(D|H) = \frac{P(H|D)P(D)}{P(H|D)P(D) + P(H|\neg D)P(\neg D)}$ Expanded Version

--

$P(D|H) = \frac{P(H|D)P(D)}{\Sigma P(H|D_i)P(D_i)}$

--

$P(D|H) = \frac{P(H|D)P(D)}{\int P(H|D_i)P(D_i) dD}$

---
# Example 

Consider an example using 1,000 hypothetical studies. We imagine that only 10% of interventions are likely to have results. We adopt standard assumptions of adopting an $\alpha$, or chance of detecting an effect when one is not there of 5%. We similarly assume 80% power $\beta$, or a 20% chance of failing to detect an effect when it is not present. 

--

|                          | D=1 (effect)        | D=0 (no effect)    |
|:-------------------------|:--------------------|:-------------------|
| Data (D)                 | 100 effects         | 900 non-effects    |
| H=1 (conclude effect)    | 80 true positives   | 45 false positives |
| H=0 (conclude no effect) | 20 false negatives  | 855 true negatives |

--

> With thanks to the [Wikipedia article](https://en.wikipedia.org/wiki/Bayes%27_theorem#Cancer_rate) on this topic for inspiration for this example.

---
# Visualization

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4}

# Bayesmatrix <- matrix(c(80, 45, 20, 855), 
#                       nrow = 2, 
#                       ncol = 2, 
#                       byrow = TRUE,
#                       dimnames = list(c("H=1", 
#                                         "H=0"), 
#                                       c("D=1", 
#                                         "D=0")))

# Bayesmatrix

# mosaicplot(Bayesmatrix, 
#            main = "1,000 Hypothetical Studies",
#            color = c("blue", "gold"),
#            cex.axis = 1.0,
#            dir = c("h","v"))

# ggplot

library(ggplot2)

library(ggmosaic)

library(michigancolors)

library(tidyr)

D <- c("yes", "no", "yes", "no") # data

D <- factor(D, levels = c("yes", "no")) # order of levels

H <- c("yes", "yes", "no", "no") # hypothesis

# H <- factor(H, levels = c("yes", "no")) # order of levels

mycount <- c(80, 45, 20, 855) # count

mylabel <- c("true positive", 
             "false positive", 
             "false negative", 
             "true negative")

mylabel <- factor(mylabel, 
                  levels = c("true positive", 
                             "false positive", 
                             "false negative", 
                             "true negative"))

Bayesdata <- data.frame(D, H, mycount, mylabel)

ggplot(Bayesdata) +
  geom_mosaic(aes(x = product(D,H),
                  fill = mylabel,
                  weight = mycount), 
              divider=mosaic("v"),
              na.rm = TRUE) + 
  labs(title = "1,000 Hypothetical Studies") +
  scale_fill_manual(name = "Category",
                    values = c(michigancolors("blue"),
                               michigancolors("maize"),
                               michigancolors("tappan red"),
                               michigancolors("wave field green"))) + 
  theme_void() +
  theme(title = element_text(size=rel(2)))

```

---
# Calculations

--

$$P(\text{effect} | \text{conclude effect}) = \frac{P(\text{conclude effect} | \text{effect}) P(\text{effect})}{P(\text{conclude effect})}$$

--

$$=\frac{P(\text{conclude effect} | \text{effect}) P(\text{effect})}{P(\text{conclude effect} | \text{effect}) P(\text{effect}) + P(\text{conclude effect} | \text{no effect}) P(\text{no effect})}$$

--

$$P(\text{effect} | \text{conclude effect}) = \frac{.8 \times .1}{.08 + .045} = .64$$

--

> See also [Thinking Through Bayesian Ideas](https://agrogan.shinyapps.io/Thinking-Through-Bayes/)

---
# Discussion

--
* Calculations suggest that a true effect is likely in 64% of the cases where one concludes the presence of an effect.

--

* Consequently, calculations suggest that 36% of the time, when one concludes there is an effect, there is actually no effect. 

--

* Put another way, despite setting $\alpha = .05$, 36% of cases result in a false positive.





